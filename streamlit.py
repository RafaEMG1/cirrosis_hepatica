# Cargue de librer√≠as
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
import kagglehub
import os
import altair as alt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OrdinalEncoder
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
from sklearn.feature_selection import mutual_info_classif
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.feature_selection import f_classif
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.model_selection import cross_val_score
from numpy import mean
from numpy import std
from sklearn.datasets import make_regression
from sklearn.feature_selection import f_regression
from sklearn.feature_selection import mutual_info_regression
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
from sklearn.tree import DecisionTreeRegressor
from sklearn.feature_selection import RFE
from sklearn.linear_model import Perceptron
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from matplotlib import pyplot
from sklearn.feature_selection import RFE
from sklearn.feature_selection import RFECV
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer


from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score
import streamlit as st
from graphviz import Digraph

import warnings
warnings.filterwarnings("ignore")


st.set_page_config(page_title="Cirrosis Hepatica Streamlit App", layout="wide")
st.title("Clasificaci√≥n de los estadios de la cirrosis hep√°tica con m√©todos de Machine Learning")

# ----------------------------
# Secci√≥n de Metodolog√≠a
# ----------------------------
st.title("üß™ Metodolog√≠a del Proyecto")

st.markdown("""
Este proyecto sigue una **metodolog√≠a de Machine Learning** para la clasificaci√≥n de la cirrosis hep√°tica.  
A continuaci√≥n, se presentan los pasos de manera interactiva:
""")

# Paso 1
with st.expander("üìå Paso 1: Carga y An√°lisis Exploratorio de Datos"):
    st.write("""
    - Se utiliz√≥ un dataset con informaci√≥n cl√≠nica de pacientes.  
    - El archivo fue almacenado en GitHub y cargado en streamlit.  
    - Se revis√≥ la calidad de los datos para identificar valores nulos
    - Se crean dos secciones con filtros para revisar las variables categ√≥ricas y num√©ricas.
    """)

# Paso 2
with st.expander("üìå Paso 2: Preprocesamiento"):
    st.write("""
    - Limpieza de datos: imputaci√≥n de valores faltantes.  
    - Codificaci√≥n de variables categ√≥ricas (One-Hot Encoding).  
    - Estandarizaci√≥n de las variables num√©ricas.  
    """)

# Paso 3
with st.expander("üìå Paso 3: Selecci√≥n de caracter√≠sticas"):
    st.write("""
    - Se utilizaron t√©cnicas de filtrado de variables como: 
        - Variables categ√≥ricas: $\chi^2$ e informaci√≥n mutua
        - Variables num√©ricas: ANOVA e informaci√≥n mutua
    - MCA y PCA
    - RFE (Recursive Feature Elimination) con validaci√≥n cruzada (selecci√≥n por envoltura)
    - Esto permite quedarnos solo con las variables m√°s relevantes para el modelo.  
    """)

# Paso 4
with st.expander("üìå Paso 4: Entrenamiento del modelo"):
    st.write("""
    - Se probaron algoritmos como **Decission tree**, **Regresi√≥n Log√≠stica**, **Random forest**, **KNN (K-Nearest Neighbors)** y **SVM (Support Vector Machine)**.  
    -   
    """)

# Paso 5
with st.expander("üìå Paso 5: Evaluaci√≥n"):
    st.write("""
    - Se calcularon m√©tricas como **Accuracy, Precision, Recall y F1-Score**.  
    - Tambi√©n se aplic√≥ validaci√≥n cruzada para obtener una estimaci√≥n m√°s robusta.  
    """)

st.subheader("üîé Flujo Metodol√≥gico")

dot = Digraph()

dot.node("A", "Carga de Datos", shape="box")
dot.node("B", "Preprocesamiento", shape="box")
dot.node("C", "Selecci√≥n de caracter√≠sticas", shape="box")
dot.node("D", "Entrenamiento del modelo\n(Logistic Regression, SVM)", shape="box")
dot.node("E", "Evaluaci√≥n del modelo\n(Accuracy, Recall, F1-Score)", shape="box")

dot.edges(["AB", "BC", "CD", "DE"])

st.graphviz_chart(dot)

st.caption("Estudio cl√≠nico de cirrosis hep√°tica ‚Äî ficha de variables")

texto = """
### **Variables:**

* **N_Days**: N√∫mero de d√≠as transcurridos entre el registro y la fecha m√°s temprana entre fallecimiento, trasplante o an√°lisis del estudio en 1986.  
* **Status**: estado del paciente C (censurado), CL (censurado por tratamiento hep√°tico) o D (fallecimiento).  
* **Drug**: tipo de f√°rmaco: D-penicilamina o placebo.  
* **Age**: edad en d√≠as.  
* **Sex**: M (hombre) o F (mujer).  
* **Ascites**: presencia de ascitis N (No) o Y (S√≠).  
* **Hepatomegaly**: presencia de hepatomegalia N (No) o Y (S√≠).  
* **Spiders**: presencia de aracnosis N (No) o Y (S√≠).  
* **Edema**: presencia de edema N (sin edema ni tratamiento diur√©tico), S (edema presente sin diur√©ticos o resuelto con diur√©ticos) o Y (edema a pesar del tratamiento diur√©tico).  
* **Bilirubin**: bilirrubina s√©rica en mg/dl.  
* **Cholesterol**: colesterol s√©rico en mg/dl.  
* **Albumin**: alb√∫mina en g/dl.  
* **Copper**: cobre en orina en ¬µg/d√≠a.  
* **Alk_Phos**: fosfatasa alcalina en U/litro.  
* **SGOT**: SGOT en U/ml.  
* **Tryglicerides**: triglic√©ridos en mg/dl.  
* **Platelets**: plaquetas por metro c√∫bico [ml/1000].  
* **Prothrombin**: tiempo de protrombina en segundos.  
* **Stage**: estadio histol√≥gico de la enfermedad (1, 2 o 3).  

---

### **Dimensiones del dataset**
- **Tama√±o:** 25 000 filas, 19 columnas  
- **Faltantes:** 0% en todas las columnas  

---
"""

st.markdown(texto)

# --- Cargar dataset ---
# URL del CSV en GitHub (raw)
url = "https://raw.githubusercontent.com/DiegoNaranjo84/cirrosis_hepatica/main/liver_cirrhosis.csv"

# Cargar el dataset
df = pd.read_csv(url)

# Filtrar solo columnas categ√≥ricas (tipo "object" o "category")
df['Stage'] = pd.to_numeric(df['Stage'], errors='coerce')
df['Stage'] = pd.Categorical(df['Stage'], ordered=True)
cat_cols = df.select_dtypes(include=['object', 'category'])

st.subheader("Primeras 10 filas del dataset")
st.dataframe(df.head(10), use_container_width=True)

# ------- Helpers -------
def format_uniques(series, max_items=20):
    """Convierte valores √∫nicos a una cadena legible, acota a max_items."""
    uniques = pd.Series(series.dropna().unique())
    head = uniques.head(max_items).astype(str).tolist()
    txt = ", ".join(head)
    if uniques.size > max_items:
        txt += f" ‚Ä¶ (+{uniques.size - max_items} m√°s)"
    return txt

# ------- Detectar tipos -------
cat_cols = df.select_dtypes(include=["object", "category"]).columns.tolist()
num_cols = df.select_dtypes(include=["number"]).columns.tolist()

# ------- Resumen variables categ√≥ricas -------
cat_summary = pd.DataFrame({
    "Variable": cat_cols,
    "Tipo de dato": [df[c].dtype for c in cat_cols],
    "N¬∫ de categor√≠as √∫nicas": [df[c].nunique(dropna=True) for c in cat_cols],
    "N¬∫ de datos no nulos": [df[c].notna().sum() for c in cat_cols],
    "Categor√≠as": [format_uniques(df[c], max_items=20) for c in cat_cols],
})

# ------- Resumen variables num√©ricas -------
num_summary = pd.DataFrame({
    "Variable": num_cols,
    "Tipo de dato": [df[c].dtype for c in num_cols],
    "N¬∫ de datos no nulos": [df[c].notna().sum() for c in num_cols],
    "M√≠nimo": [df[c].min(skipna=True) for c in num_cols],
    "M√°ximo": [df[c].max(skipna=True) for c in num_cols],
    "Media":  [df[c].mean(skipna=True) for c in num_cols],
    "Desviaci√≥n est√°ndar": [df[c].std(skipna=True) for c in num_cols],
}).round(2)

# ------- Mostrar en dos columnas iguales con separaci√≥n uniforme -------
col1, col2 = st.columns(2, gap="large")

with col1:
    st.subheader("Resumen variables categ√≥ricas")
    st.dataframe(cat_summary, use_container_width=True)

with col2:
    st.subheader("Resumen variables num√©ricas")
    st.dataframe(num_summary, use_container_width=True)

#####--------------------------------------------------------------------------------------#########

st.markdown("""### An√°lisis de variables categ√≥ricas""")
st.caption("Selecciona una variable para ver su distribuci√≥n en tabla y gr√°fico de torta.")

variables_categoricas = df.select_dtypes(include=["object", "category", "bool"]).columns.tolist()

if not variables_categoricas:
    st.warning("No se detectaron variables categ√≥ricas (object/category/bool) en df.")
    st.stop()

# =========================
# Controles (En la secci√≥n)
# =========================
st.markdown("*Controles*")
with st.container():
    c1, c2 = st.columns([1.6, 1.1])
    with c1:
        var = st.selectbox(
            "Variable categ√≥rica",
            options=variables_categoricas,
            index=0,
            key="cat_var_local"
        )
        top_n = st.slider(
            "Top N (agrupa el resto en 'Otros')",
            min_value=3, max_value=30, value=10, step=1,
            help="Agrupa las categor√≠as menos frecuentes en 'Otros'",
            key="cat_topn_local"
        )
    with c2:
        orden_alfabetico = st.checkbox("Ordenar alfab√©ticamente (solo tabla)", value=False, key="cat_orden_local")

# =========================
# Preparar datos (siempre incluye NaN)
# =========================
serie = df[var].copy()

vc = serie.value_counts(dropna=True)  # Se mantienen los NaN para contarlos

# Etiqueta amigable para NaN
labels = vc.index.to_list()
labels = ["(NaN)" if (isinstance(x, float) and np.isnan(x)) else str(x) for x in labels]
counts = vc.values

data = pd.DataFrame({"Categor√≠a": labels, "Conteo": counts})
data["Porcentaje"] = (data["Conteo"] / data["Conteo"].sum() * 100).round(2)

# Agrupar en "Otros" si supera Top N
if len(data) > top_n:
    top = data.nlargest(top_n, "Conteo").copy()
    otros = data.drop(top.index)
    fila_otros = pd.DataFrame({
        "Categor√≠a": ["Otros"],
        "Conteo": [int(otros["Conteo"].sum())],
        "Porcentaje": [round(float(otros["Porcentaje"].sum()), 2)]
    })
    data_plot = pd.concat([top, fila_otros], ignore_index=True)
else:
    data_plot = data.copy()

# Orden por Conteo (siempre)
data_plot = data_plot.sort_values("Conteo", ascending=False).reset_index(drop=True)

# Orden opcional alfab√©tico en la tabla (no afecta el gr√°fico)
data_table = data_plot.copy()
if orden_alfabetico:
    data_table = data_table.sort_values("Categor√≠a").reset_index(drop=True)

# =========================
# Mostrar tabla y gr√°fico
# =========================
tcol, gcol = st.columns([1.1, 1.3], gap="large")

with tcol:
    st.subheader(f"Distribuci√≥n de {var}")
    st.dataframe(
        data_table.assign(Porcentaje=data_table["Porcentaje"].round(2)),
        use_container_width=True
    )

with gcol:
    st.subheader("Gr√°fico de torta")
    chart = (
        alt.Chart(data_plot)
        .mark_arc(outerRadius=110)
        .encode(
            theta=alt.Theta(field="Conteo", type="quantitative"),
            color=alt.Color("Categor√≠a:N", legend=alt.Legend(title="Categor√≠a")),
            tooltip=[
                alt.Tooltip("Categor√≠a:N"),
                alt.Tooltip("Conteo:Q", format=","),
                alt.Tooltip("Porcentaje:Q", format=".2f")
            ],
        )
        .properties(height=380)
    )
    st.altair_chart(chart, use_container_width=True)

# =========================
# Extras informativos
# =========================
st.divider()
c1, c2 = st.columns(2)
with c1:
    st.metric("Categor√≠as mostradas", f"{len(data_plot)}")
with c2:
    st.metric("Total registros (variable seleccionada)", f"{int(serie.shape[0]):,}".replace(",", "."))

st.caption("Consejo: usa *Top N* para simplificar la lectura y agrupar categor√≠as poco frecuentes en 'Otros'.")

#####--------------------------------------------------------------------------------------#########

# =========================
# An√°lisis de variables num√©ricas
# =========================
st.markdown("""### An√°lisis de variables num√©ricas""")
st.caption("Selecciona una variable para ver su distribuci√≥n en tabla, boxplot e histograma.")

# Detectar variables num√©ricas
variables_numericas = df.select_dtypes(include=["number"]).columns.tolist()

if not variables_numericas:
    st.warning("No se detectaron variables num√©ricas en df.")
    st.stop()

# =========================
# Controles dentro de la secci√≥n
# =========================
st.markdown("*Controles*")
with st.container():
    c1, c2 = st.columns([1.6, 1.4])
    with c1:
        var_num = st.selectbox(
            "Variable num√©rica",
            options=variables_numericas,
            index=0,
            key="num_var_local"
        )
    with c2:
        bins = st.slider(
            "N√∫mero de bins (histograma)",
            min_value=5, max_value=100, value=30, step=5,
            key="num_bins_local"
        )

# =========================
# Preparar serie
# =========================
serie_num = df[var_num].dropna()

# =========================
# M√©tricas descriptivas
# =========================
c1, c2, c3, c4, c5 = st.columns(5)
with c1:
    st.metric("N¬∫ datos no nulos", f"{serie_num.shape[0]:,}".replace(",", "."))
with c2:
    st.metric("M√≠nimo", f"{serie_num.min():.2f}")
with c3:
    st.metric("M√°ximo", f"{serie_num.max():.2f}")
with c4:
    st.metric("Media", f"{serie_num.mean():.2f}")
with c5:
    st.metric("Desv. Est√°ndar", f"{serie_num.std():.2f}")

# =========================
# Gr√°ficos
# =========================
g1, g2 = st.columns(2, gap="large")

# --- Boxplot vertical y ancho ---
with g1:
    st.subheader(f"Boxplot de {var_num} ")
    box_data = pd.DataFrame({var_num: serie_num})
    box_data["_grupo_"] = "Distribuci√≥n"  # ancla un grupo √∫nico en X

    box_chart = (
        alt.Chart(box_data)
        .mark_boxplot(size=140, extent=1.5)  # size = ancho de la caja; extent=1.5 => whiskers tipo Tukey
        .encode(
            x=alt.X("_grupo_:N", axis=None, title=""),
            y=alt.Y(f"{var_num}:Q", title=var_num)
        )
        .properties(height=350)
    )
    st.altair_chart(box_chart, use_container_width=True)

# --- Histograma ---
with g2:
    st.subheader(f"Histograma de {var_num}")
    hist_data = pd.DataFrame({var_num: serie_num})
    hist_chart = (
        alt.Chart(hist_data)
        .mark_bar()
        .encode(
            alt.X(var_num, bin=alt.Bin(maxbins=bins)),
            y='count()',
            tooltip=[
                alt.Tooltip(var_num, bin=alt.Bin(maxbins=bins)),
                alt.Tooltip('count()', title="Frecuencia")
            ]
        )
        .properties(height=350)
    )
    st.altair_chart(hist_chart, use_container_width=True)

# =========================
# Matriz de Correlaci√≥n
# =========================
st.markdown("### Matriz de Correlaci√≥n")
correlacion = df.corr(numeric_only=True)
fig, ax = plt.subplots(figsize=(10, 8))
sns.heatmap(correlacion, annot=True, cmap='coolwarm', fmt=".2f", ax=ax)
ax.set_title("Matriz de Correlaci√≥n")
st.pyplot(fig)
#________________________________________________________________________________________________________________________________________________________________




# ________________________________________________________________________________________________________________________________________________________________
st.markdown("""# 1. Selecci√≥n de car√°cteristicas""")
# ________________________________________________________________________________________________________________________________________________________________
st.markdown("""## 1.1. Selecci√≥n de car√°cteristicas categ√≥ricas""")
# ________________________________________________________________________________________________________________________________________________________________
st.markdown("""## 1.2. Selecci√≥n de car√°cteristicas num√©ricas""")
# ________________________________________________________________________________________________________________________________________________________________
st.markdown("""## 1.3. Uni√≥n de variables categ√≥ricas y n√∫mericas""")



# ________________________________________________________________________________________________________________________________________________________________
st.markdown("""# 2. MCA Y PCA""")
# ________________________________________________________________________________________________________________________________________________________________
st.markdown("""## 2.1. MCA""")
# ________________________________________________________________________________________________________________________________________________________________
st.markdown("""## 2.2. PCA""")
# ________________________________________________________________________________________________________________________________________________________________
st.markdown("""# 3. RFE""")

# ______________________________________________________

st.markdown("""# 3. RFE""")

# Convertir Stage a categ√≥rica
df["Stage"] = df["Stage"].astype("category")

# Definir variables categ√≥ricas y num√©ricas
categorical = df.select_dtypes(include=["object","category"])
categorical_features = categorical.columns.drop("Stage").tolist()
numerical_features = df.select_dtypes(include=["int64","float64"]).columns.tolist()

# Separar X e y
X = df[categorical_features + numerical_features]
y = df["Stage"]

# Partici√≥n train-test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.33, random_state=42, stratify=y
)

# OneHotEncoder compatible con distintas versiones de sklearn
try:
    OHE = OneHotEncoder(handle_unknown="ignore", sparse_output=False)
except TypeError:
    OHE = OneHotEncoder(handle_unknown="ignore", sparse=False)

# Preprocesador
preprocessor = ColumnTransformer(
    transformers=[
        ("num", "passthrough", numerical_features),
        ("cat", OHE, categorical_features),
    ]
)

# Modelos disponibles
models = {
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
}

# ---- Control: seleccionar 1 modelo (por defecto Random Forest) ----
model_names = list(models.keys())
default_index = model_names.index("Decision Tree") if "Random Forest" in model_names else 0
modelo_elegido = st.selectbox("Modelo a ejecutar", options=model_names, index=default_index, key="rfe_modelo")
model = models[modelo_elegido]

st.title("Resultados de Selecci√≥n de Caracter√≠sticas con RFE-CV")
st.subheader(f"Modelo: {modelo_elegido}")

# RFECV
rfe = RFECV(
    estimator=model,
    step=1,
    cv=RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42),
    scoring="accuracy",
    n_jobs=-1,
)

# Pipeline
pipeline = Pipeline([
    ("preprocessor", preprocessor),
    ("feature_selection", rfe),
    ("model", model),
])

# Entrenar
pipeline.fit(X_train, y_train)

# Evaluar
accuracy_test = pipeline.score(X_test, y_test)
mask = pipeline.named_steps["feature_selection"].support_
feature_names = pipeline.named_steps["preprocessor"].get_feature_names_out()
selected_names = feature_names[mask]

# Mostrar en la app
st.write(f"*Accuracy en test set:* {accuracy_test:.3f}")
st.write(f"*Variables seleccionadas:* {len(selected_names)}")
st.write(f"*Nombres:* {list(selected_names)}")

# Resumen final (solo el modelo elegido)
st.header("Resumen Final")
st.markdown(f"""
*Modelo:* {modelo_elegido}  
- Accuracy: {accuracy_test:.3f}  
- Variables seleccionadas: {len(selected_names)}  
- Nombres: {list(selected_names)}  
""")

